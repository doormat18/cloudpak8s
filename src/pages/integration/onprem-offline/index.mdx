---
title: VMware using Offline Images
weight: 400
---

- [Setting the max_map_count](#setting-the-max_map_count)
- [Download and extract the image](#download-and-extract-the-image)
- [Creating config.yaml](#creating-configyaml)
- [Creating getAllRec.sh](#creating-getallrecsh)
- [Starting the install process](#starting-the-install-process)
- [Creating the correct kubeconfig](#creating-the-correct-kubeconfig)
- [Uninstalling Common Services](#uninstalling-common-services)

**NOTE: Make sure you have 200GB or more on your installer node. If you have less, then you can download the offline image, extract and delete the original file**

## Setting the max_map_count

SSH into all your worker and storage nodes and set the max_map_count to 262144.

```bash
sudo sysctl -w vm.max_map_count=262144
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
```

## Download and extract the image

SSH into your installer node. Go to `/opt` dir and download the image there. Look at [Pre-requisites](../pre-reqs) to learn how to get the offline image.

```bash
cd /opt
mkdir cp4ioffline
tar xf ibm-cp-int-2019.4.1-offline.tar.gz --directory /opt/cp4ioffline
```

Now you can extract the images and load them into docker.

```bash
cd cp4ioffline
tar xvf installer_files/cluster/images/common-services-armonk-x86_64.tar.gz -O | sudo docker load
```

You can delete `ibm-cp-int-2019.4.1-offline.tar.gz` now if you're low on space.

## Creating config.yaml

Now you have to configure your `cp4ioffline/installer_files/cluster/config.yaml`. It is always a good idea to create a backup of the default `cluster.yaml`.

 - You can use your OpenShift master and infrastructure nodes here, or install these components to dedicated OpenShift compute nodes. You can specify more than one node for each type to build a high availability cluster. Use the command `oc get nodes` to obtain these values.
  ```yaml
  cluster_nodes:
  master:
    - your-openshift-dedicated-node-to-deploy-icp-master-components
  proxy:
    - your-openshift-dedicated-node-to-deploy-icp-proxy-components>
  management:
    - your-openshift-dedicated-node-to-deploy-icp-management-components>
  ```

  - Set the default_admin_password. The password must meet the default password enforcement rule '^([a-zA-Z0-9\-]{32,})$' . Optionally, you can define one or more rules as regular expressions in an array list that the password must pass. The rules are written as regular expressions that are supported by the Go programming language. To define a set of password rules, add the following parameter and values to the file:

  ```yaml
    password_rules:
    - '^.{10,}'
    - '.*[!@#\$%\^&\*].*'
  ``` 
  To disable the password_rule, add (.*).

  ```yaml
    password_rules:
    - '(.*)'
  ```

  - Finally, you'll have define what capabilities you would like to install under `archive_addons:`. By default it installs all the capabilities. But depending on your requirements, you can pick and choose. For example defined below is a cluster with `mq` and `tracing`
  **Note: You must deploy `icp4i` also referred to as common services, otherwise you can't deploy any other capabilities**

  ```yaml
    archive_addons:
      icp4i:
        namespace: integration
        repo: local-charts
        path: icp4icontent/IBM-Cloud-Pak-for-Integration-3.0.0.tgz
        charts:
          - name: ibm-icp4i-prod
            values: {}
      mq:
        namespace: mq
        repo: local-charts
        path: icp4icontent/IBM-MQ-Advanced-for-IBM-Cloud-Pak-for-Integration-5.0.0.tgz
      tracing:
        namespace: tracing
        repo: local-charts
        path: icp4icontent/IBM-Cloud-Pak-for-Integration-Operations-Dashboard-1.0.1.tgz
      
   
  ```

  Additionally, here is an example that deploys everything [`config.yaml`](/assets/integration/utils/config.yaml)

## Creating getAllRec.sh

When the installer fails, this script will echo all the pods that are up and running and pods that are failing.

```bash
cd /opt
touch getAllRec.sh
sudo chmod 755 getAllRec.sh
```

You can get the [`getAllRec.sh`](/assets/integration/utils/getAllRec.sh) file from here.

To run `getAllRec.sh` you need to pass in a namespace. Usually on a failed install, the `kube-system` namespace gives us the most information regarding the failure.

```bash
./getAllRec.sh kube-system
```

## Creating the correct kubeconfig

First you have to copy our kubeconfig to the cluster directory. 

```bash
cd /opt/cp4ioffline/installer_files/cluster
oc config view --minify=true --flatten=true > kubeconfig
```

It should look similar to this. **Note:** Make sure it has `insecure-skip-tls-verify: true`config.

```yaml
apiVersion: v1
clusters:
- cluster:
    insecure-skip-tls-verify: true
    server: https://api.mislam.ocp.csplab.local:6443
  name: api-mislam-ocp-csplab-local:6443
contexts:
- context:
    cluster: api-mislam-ocp-csplab-local:6443
    namespace: openshift-image-registry
    user: kube:admin/api-mislam-ocp-csplab-local:6443
  name: openshift-image-registry/api-mislam-ocp-csplab-local:6443/kube:admin
current-context: openshift-image-registry/api-mislam-ocp-csplab-local:6443/kube:admin
kind: Config
preferences: {}
users:
- name: kube:admin/api-mislam-ocp-csplab-local:6443
  user:
    token: 3lg2U7vUcu-ovvsrK-sYDSWg3t5vLcBPY83DkvL44Is
```

**Alternatively** you can copy it from our Openshift Cluster Auth directory to here. 

```bash
cp /opt/myocpcluster/auth/kubeconfig /opt/cp4ioffline/installer_files/cluster
```

## Checking Docker Login

Run this command to see if you can login to docker 

```bash
sudo docker login $(oc registry info) -u kubeadmin -p $(oc whoami -t)
```

## Starting the install process

Now you run the installer. Notice it's a nohup job (runs on the background) and the logs are written to `install.log` so you can close your terminal and leave but the installer will keep on going on the server. And log back in and look at `install.log` to see progress.

```bash
nohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 addon -vvv | tee install.log &
```

**NOTE: If the installer fails, run the getAllRec.sh script to check if common services is up or not. If it isn't up, you can run the installer again. If it is up but one of the capabilities failed tyo get pushed, then that capability can be applied individually** 
## Uninstalling Common Services

In case the installer fails on the same step multiple times, it's better to uninstall and try again. To uninstall

```bash
nohup sudo docker run -t --net=host -e LICENSE=accept -v $(pwd):/installer/cluster:z -v /var/run:/var/run:z -v /etc/docker:/etc/docker:z --security-opt label:disable ibmcom/icp-inception-amd64:3.2.2 uninstall-with-openshift | tee install.log &
```


